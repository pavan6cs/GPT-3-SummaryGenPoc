{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of GPT3 Article Master Upload.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pavan6cs/GPT-3-SummaryGenPoc/blob/main/Copy_of_GPT3_Article_Master_Upload.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZBpIXFmzbYL"
      },
      "source": [
        "**Installing required packages**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHp66-cfG-TW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 944
        },
        "outputId": "9faa5ae9-6927-4b3a-a3a6-7bc4fdd6e4a7"
      },
      "source": [
        "!pip install openai\n",
        "!pip install gpt3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-0.10.1.tar.gz (155 kB)\n",
            "\u001b[?25l\r\u001b[K     |██                              | 10 kB 16.0 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 20 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 30 kB 22.3 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 40 kB 25.1 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 51 kB 28.1 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 61 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 71 kB 31.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 81 kB 32.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 92 kB 33.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 102 kB 31.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 112 kB 31.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 122 kB 31.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 133 kB 31.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 143 kB 31.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 153 kB 31.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 155 kB 31.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.7/dist-packages (from openai) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from openai) (4.41.1)\n",
            "Collecting pandas>=1.2.3\n",
            "  Downloading pandas-1.3.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.5 MB 32.8 MB/s \n",
            "\u001b[?25hCollecting pandas-stubs>=1.1.0.11\n",
            "  Downloading pandas_stubs-1.2.0.1-py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 45.4 MB/s \n",
            "\u001b[?25hCollecting openpyxl>=3.0.7\n",
            "  Downloading openpyxl-3.0.7-py2.py3-none-any.whl (243 kB)\n",
            "\u001b[K     |████████████████████████████████| 243 kB 48.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: et-xmlfile in /usr/local/lib/python3.7/dist-packages (from openpyxl>=3.0.7->openai) (1.1.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.3->openai) (2018.9)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.3->openai) (1.19.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.3->openai) (2.8.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from pandas-stubs>=1.1.0.11->openai) (3.7.4.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.2.3->openai) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->openai) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->openai) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->openai) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->openai) (2.10)\n",
            "Building wheels for collected packages: openai\n",
            "  Building wheel for openai (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai: filename=openai-0.10.1-py3-none-any.whl size=167551 sha256=43073024f6b869f3bb5b8459effb803f3e6678ef6707337f15d7c7f312317873\n",
            "  Stored in directory: /root/.cache/pip/wheels/06/90/44/74a9536b153b7ca2fcadaf316a552a2018fd298b95c153af05\n",
            "Successfully built openai\n",
            "Installing collected packages: pandas-stubs, pandas, openpyxl, openai\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.1.5\n",
            "    Uninstalling pandas-1.1.5:\n",
            "      Successfully uninstalled pandas-1.1.5\n",
            "  Attempting uninstall: openpyxl\n",
            "    Found existing installation: openpyxl 2.5.9\n",
            "    Uninstalling openpyxl-2.5.9:\n",
            "      Successfully uninstalled openpyxl-2.5.9\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas~=1.1.0; python_version >= \"3.0\", but you have pandas 1.3.1 which is incompatible.\u001b[0m\n",
            "Successfully installed openai-0.10.1 openpyxl-3.0.7 pandas-1.3.1 pandas-stubs-1.2.0.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pandas"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting gpt3\n",
            "  Downloading gpt3-0.0.1-py3-none-any.whl (2.0 kB)\n",
            "Installing collected packages: gpt3\n",
            "Successfully installed gpt3-0.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtFnG_XhG-Tn",
        "scrolled": true
      },
      "source": [
        "#import the necessary libraries\n",
        "import json\n",
        "import openai\n",
        "from gpt import GPT #you can get the gpt.py file from here - https://github.com/shreyashankar/gpt3-sandbox/blob/master/api/gpt.py\n",
        "from gpt import Example\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PsuPXUDz3Q1"
      },
      "source": [
        "**Openai key and gpt initialization**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVxGpZu1G-Tp"
      },
      "source": [
        "openai.api_key = \"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\" # You need to request the folks at OpenAI for an api key, so that you can start playing around with GPT-3\n",
        "gpt = GPT(engine=\"davinci\",\n",
        "          temperature=0.5,\n",
        "          max_tokens=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTYlQxki92vf"
      },
      "source": [
        "**Iteration 1 - General Summary of the Meeting**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHKFlevL995D"
      },
      "source": [
        "# We'll be using the below text for our first iteration - To generate summary for a Stand-up Call (The below transcript was generated by Google STT)\n",
        "prompt = \"\"\"Transcript\n",
        "Darshan Melgiri:Hello everyone. Can you please let me know where do we stand in terms of the use case on the gpt3, which you are working on.\n",
        "pavan kumar S:Okay, so, I was working on the use case for react code conversion And code generation also. So on the code generation part, I tried with multiple examples, the accuracy is very less, it comes to 50%. And also if there is a slight deviation in the prompt or something, it gives very bad results. So I think shouldn't consider this code conversion or generation use-case as a right fit using GPT-3.\n",
        "Darshan Melgiri:So do you have any iterations of the training that you have done before you conclude that it is not right Use case to work with GPT 3?\n",
        "pavan kumar S:Yes, I have taken 10 examples and trained with it, then asked the same questions, like if I take an example of generating a DIV, then ask a DIV with some text, it will give the correct results. But, if I take a form, and if I give form a button, And train it. Then again, if I ask a form with two fields and two buttons, it doesn't give the right result. So basic component, it's not able to generate So that's why I think it's not a good use case and it's failing. It\n",
        "Darshan Melgiri: Okay, so if I have to consider it right in terms of the code conversion or generation, it is better to exclude gpt3 And then build our own self products rather than relying upon the openAI platform. \n",
        "Darshan Melgiri : So also I wanted to update that I was working on this Text summarization use case. So this is coming out pretty well. So we have went with a different approaches. \n",
        "Darshan Melgiri : So basically three approaches were put in place. One approach was directly taking the entire conversation and extracting the summary. The second approach was mostly in terms of Taking the topics with respect to one individual and then briefing, it accordingly. The third one was To ensure to move the window size. Starting from let's say first five lines, followed by the next five and see how the results were getting generated to be very honest. For the first two approaches, it was not that great, but while we put on the moving Windows Slide the results were getting better. So yet to understand if it still works for this particular use case.\n",
        "pavan kumar S: Okay, cool.\n",
        "Darshan Melgiri : Okay, then, so if I have to summarize, then the use case on the text summarization using gpt3 is pretty good. So it's a thumbs up for that and thumbs down for the use cases Wherein gpt3 is used for the code conversion or the code Migration part of it. Is that correct?\n",
        "pavan kumar S:Yes, absolutely.\n",
        "Darshan Melgiri: Oh okay. Okay then so let's see how do we progress further? Thanks man.\n",
        "pavan kumar S: Thank you.\n",
        "\n",
        "Summarise in 10 lines\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwtBf1S9-tpU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a500dd28-92a3-4ad5-849f-6a1ced034896"
      },
      "source": [
        "# This should get you the summary for the transcript above\n",
        "response = openai.Completion.create(\n",
        "  engine=\"davinci-instruct-beta\",\n",
        "  prompt=prompt,\n",
        "  temperature=0.25,\n",
        "  max_tokens=100,\n",
        "  top_p=1\n",
        ")\n",
        "print(response)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"finish_reason\": \"length\",\n",
            "      \"index\": 0,\n",
            "      \"logprobs\": null,\n",
            "      \"text\": \"\\n\\nThe speaker is Darshan Melgiri and he is talking to Pavan Kumar S.\\n\\nDarshan Melgiri: \\\"Hello everyone. Can you please let me know where do we stand in terms of the use case on the gpt3, which you are working on.\\\"\\nPavan Kumar S: \\\"Okay, so, I was working on the use case for react code conversion And code generation also. So on the code generation part, I tried with multiple\"\n",
            "    }\n",
            "  ],\n",
            "  \"created\": 1627387801,\n",
            "  \"id\": \"cmpl-3QGCHb7kY1teHJpjzWNavT80oXPi0\",\n",
            "  \"model\": \"if-davinci-v2\",\n",
            "  \"object\": \"text_completion\"\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7SAw7Oo4zQG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiSF3mkfA5Uh"
      },
      "source": [
        "**Iteration 2 - Summary of what the individual members had to say in the meeting**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgNLsabCB2vp"
      },
      "source": [
        "*The two actors- Team Lead and team member*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOOHWWTpCfjS"
      },
      "source": [
        "# The below block of text contains everything the team lead said in the meeting\n",
        "prompt_ashwin = \"\"\"\n",
        "pavan kumar S:Okay, so, I was working on the use case for react code conversion And code generation also. So on the code generation part, I tried with multiple examples, the accuracy is very less, it comes to 50%. And also if there is a slight deviation in the prompt or something, it gives very bad results. So I think shouldn't consider this code conversion or generation use-case as a right fit using GPT-3.\n",
        "pavan kumar S:Yes, I have taken 10 examples and trained with it, then asked the same questions, like if I take an example of generating a DIV, then ask a DIV with some text, it will give the correct results. But, if I take a form, and if I give form a button, And train it. Then again, if I ask a form with two fields and two buttons, it doesn't give the right result. So basic component, it's not able to generate So that's why I think it's not a good use case and it's failing. It\n",
        "pavan kumar S: Okay, cool.\n",
        "pavan kumar S: Thank you.\n",
        "pavan kumar S:Yes, absolutely.\n",
        "Summarise in 10 lines\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCf43-KwDaBe"
      },
      "source": [
        "# The below block of text contains everything the team member said in the meeting\n",
        "prompt_shashank = \"\"\"\n",
        "Darshan Melgiri : Hello everyone. Can you please let me know where do we stand in terms of the use case on the gpt3, which you are working on.\n",
        "Darshan Melgiri : So do you have any iterations of the training that you have done before you conclude that it is not right Use case to work with GPT 3?\n",
        "Darshan Melgiri : So also I wanted to update that I was working on this Text summarization use case. So this is coming out pretty well. So we have went with a different approaches. \n",
        "Darshan Melgiri : So basically three approaches were put in place. One approach was directly taking the entire conversation and extracting the summary. The second approach was mostly in terms of Taking the topics with respect to one individual and then briefing, it accordingly. The third one was To ensure to move the window size. Starting from let's say first five lines, followed by the next five and see how the results were getting generated to be very honest. For the first two approaches, it was not that great, but while we put on the moving Windows Slide the results were getting better. So yet to understand if it still works for this particular use case.\n",
        "Darshan Melgiri : Okay, then, so if I have to summarize, then the use case on the text summarization using gpt3 is pretty good. So it's a thumbs up for that and thumbs down for the use cases Wherein gpt3 is used for the code conversion or the code Migration part of it. Is that correct?\n",
        "Darshan Melgiri : Oh okay. Okay then so let's see how do we progress further? Thanks man.\n",
        "\n",
        "\n",
        "Summarise in 10 lines\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3p_uKXeNDxBm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "outputId": "f6a807a1-1a92-4c28-af50-809c45f3b20e"
      },
      "source": [
        "#This block of code should fetch you the individual summaries of the two text blocks above\n",
        "\n",
        "response = openai.Completion.create(\n",
        "  engine=\"davinci-instruct-beta\",\n",
        "  prompt=prompt_ashwin,\n",
        "  temperature=0.25,\n",
        "  max_tokens=100,\n",
        "  top_p=1\n",
        ")\n",
        "print(response.choices[0].text)\n",
        "\n",
        "response = openai.Completion.create(\n",
        "  engine=\"davinci-instruct-beta\",\n",
        "  prompt=prompt_shashank,\n",
        "  temperature=0.25,\n",
        "  max_tokens=100,\n",
        "  top_p=1\n",
        ")\n",
        "print(response.choices[0].text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-429052bcee54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#This block of code should fetch you the individual summaries of the two text blocks above\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m response = openai.Completion.create(\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"davinci-instruct-beta\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprompt_ashwin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'openai' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnQ5tlOlFEwJ"
      },
      "source": [
        "**Iteration 3 - The Moving Window Technique**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txnNKhgAFUVq"
      },
      "source": [
        "*There's pre-processing involved (as always) before the experimentation*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_ZP8aY0G-Tr"
      },
      "source": [
        "# We'll be using a .txt file of the transcript of the meet\n",
        "with open('transcript.txt') as f:\n",
        "    mylist = list(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IgAQY-6q7PLg"
      },
      "source": [
        "**The Necessary Pre-Processing Steps**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ekVZ94RG-Tw"
      },
      "source": [
        "#remove the predominant '\\n','  \\n' and the first element of the list\n",
        "text = list(filter(('\\n').__ne__, mylist))\n",
        "text = list(filter(('  \\n').__ne__, text))\n",
        "text = text[1:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gu53PMrG-Ty"
      },
      "source": [
        "#remove the \\n characters that are appended to the strings\n",
        "next_text = []\n",
        "for string in text:\n",
        "    next_text.append(string.replace('\\n',''))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7HX3QA3G-Tz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c336d92b-1438-4596-e2d4-b697e6d36074"
      },
      "source": [
        "#In a for loop, add two strings - the present and the successive, and choose the alternate strings, to get the relevant conversations\n",
        "final_text_2 = []\n",
        "for i in range(len(next_text)):\n",
        "    try:\n",
        "        final_text_2.append(next_text[i] + \" \" + next_text[i+1])       \n",
        "    except:\n",
        "        pass\n",
        "final_text_2\n",
        "\n",
        "for i in range(len(final_text_2)):\n",
        "  print(final_text_2[i]);\n",
        "print(\"----------------------------\")\n",
        "result = final_text_2[0::2]\n",
        "for i in range(len(result)):\n",
        "  print(result[i]);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pavan kumar S:Okay, so, I was working on the use case for react code conversion And code generation also. So on the code generation part, I tried with multiple examples, the accuracy is very less, it comes to 50%. And also if there is a slight deviation in the prompt or something, it gives very bad results. So I think shouldn't consider this code conversion or generation use-case as a right fit using GPT-3. Darshan Melgiri:So do you have any iterations of the training that you have done before you conclude that it is not right Use case to work with GPT 3?\n",
            "Darshan Melgiri:So do you have any iterations of the training that you have done before you conclude that it is not right Use case to work with GPT 3? pavan kumar S:Yes, I have taken 10 examples and trained with it, then asked the same questions, like if I take an example of generating a DIV, then ask a DIV with some text, it will give the correct results. But, if I take a form, and if I give form a button, And train it. Then again, if I ask a form with two fields and two buttons, it doesn't give the right result. So basic component, it's not able to generate So that's why I think it's not a good use case and it's failing. It\n",
            "pavan kumar S:Yes, I have taken 10 examples and trained with it, then asked the same questions, like if I take an example of generating a DIV, then ask a DIV with some text, it will give the correct results. But, if I take a form, and if I give form a button, And train it. Then again, if I ask a form with two fields and two buttons, it doesn't give the right result. So basic component, it's not able to generate So that's why I think it's not a good use case and it's failing. It Darshan Melgiri: Okay, so if I have to consider it right in terms of the code conversion or generation, it is better to exclude gpt3 And then build our own self products rather than relying upon the openAI platform. \n",
            "Darshan Melgiri: Okay, so if I have to consider it right in terms of the code conversion or generation, it is better to exclude gpt3 And then build our own self products rather than relying upon the openAI platform.  Darshan Melgiri : So also I wanted to update that I was working on this Text summarization use case. So this is coming out pretty well. So we have went with a different approaches. \n",
            "Darshan Melgiri : So also I wanted to update that I was working on this Text summarization use case. So this is coming out pretty well. So we have went with a different approaches.  Darshan Melgiri : So basically three approaches were put in place. One approach was directly taking the entire conversation and extracting the summary. The second approach was mostly in terms of Taking the topics with respect to one individual and then briefing, it accordingly. The third one was To ensure to move the window size. Starting from let's say first five lines, followed by the next five and see how the results were getting generated to be very honest. For the first two approaches, it was not that great, but while we put on the moving Windows Slide the results were getting better. So yet to understand if it still works for this particular use case.\n",
            "Darshan Melgiri : So basically three approaches were put in place. One approach was directly taking the entire conversation and extracting the summary. The second approach was mostly in terms of Taking the topics with respect to one individual and then briefing, it accordingly. The third one was To ensure to move the window size. Starting from let's say first five lines, followed by the next five and see how the results were getting generated to be very honest. For the first two approaches, it was not that great, but while we put on the moving Windows Slide the results were getting better. So yet to understand if it still works for this particular use case. pavan kumar S: Okay, cool.\n",
            "pavan kumar S: Okay, cool. Darshan Melgiri : Okay, then, so if I have to summarize, then the use case on the text summarization using gpt3 is pretty good. So it's a thumbs up for that and thumbs down for the use cases Wherein gpt3 is used for the code conversion or the code Migration part of it. Is that correct?\n",
            "Darshan Melgiri : Okay, then, so if I have to summarize, then the use case on the text summarization using gpt3 is pretty good. So it's a thumbs up for that and thumbs down for the use cases Wherein gpt3 is used for the code conversion or the code Migration part of it. Is that correct? pavan kumar S:Yes, absolutely.\n",
            "pavan kumar S:Yes, absolutely. Darshan Melgiri: Oh okay. Okay then so let's see how do we progress further? Thanks man.\n",
            "Darshan Melgiri: Oh okay. Okay then so let's see how do we progress further? Thanks man. pavan kumar S: Thank you.\n",
            "----------------------------\n",
            "pavan kumar S:Okay, so, I was working on the use case for react code conversion And code generation also. So on the code generation part, I tried with multiple examples, the accuracy is very less, it comes to 50%. And also if there is a slight deviation in the prompt or something, it gives very bad results. So I think shouldn't consider this code conversion or generation use-case as a right fit using GPT-3. Darshan Melgiri:So do you have any iterations of the training that you have done before you conclude that it is not right Use case to work with GPT 3?\n",
            "pavan kumar S:Yes, I have taken 10 examples and trained with it, then asked the same questions, like if I take an example of generating a DIV, then ask a DIV with some text, it will give the correct results. But, if I take a form, and if I give form a button, And train it. Then again, if I ask a form with two fields and two buttons, it doesn't give the right result. So basic component, it's not able to generate So that's why I think it's not a good use case and it's failing. It Darshan Melgiri: Okay, so if I have to consider it right in terms of the code conversion or generation, it is better to exclude gpt3 And then build our own self products rather than relying upon the openAI platform. \n",
            "Darshan Melgiri : So also I wanted to update that I was working on this Text summarization use case. So this is coming out pretty well. So we have went with a different approaches.  Darshan Melgiri : So basically three approaches were put in place. One approach was directly taking the entire conversation and extracting the summary. The second approach was mostly in terms of Taking the topics with respect to one individual and then briefing, it accordingly. The third one was To ensure to move the window size. Starting from let's say first five lines, followed by the next five and see how the results were getting generated to be very honest. For the first two approaches, it was not that great, but while we put on the moving Windows Slide the results were getting better. So yet to understand if it still works for this particular use case.\n",
            "pavan kumar S: Okay, cool. Darshan Melgiri : Okay, then, so if I have to summarize, then the use case on the text summarization using gpt3 is pretty good. So it's a thumbs up for that and thumbs down for the use cases Wherein gpt3 is used for the code conversion or the code Migration part of it. Is that correct?\n",
            "pavan kumar S:Yes, absolutely. Darshan Melgiri: Oh okay. Okay then so let's see how do we progress further? Thanks man.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWNnYwgPG-T2"
      },
      "source": [
        "#split using pm or am \n",
        "import re\n",
        "preprocess = []\n",
        "for q in result:\n",
        "    preprocess.append(q)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtqE9EaBG-T5"
      },
      "source": [
        "#function for creating windows of sentences of required length\n",
        "def window(text_list, window_size):\n",
        "    final_list = []\n",
        "    for i in range(len(text_list)):\n",
        "        try:\n",
        "            interim = text_list[i:i+window_size]\n",
        "            final_list.append(interim)\n",
        "        except:\n",
        "            pass \n",
        "    return final_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjvG-z5kG-T-"
      },
      "source": [
        "#function that returns the summarized output for the given strings/sentences\n",
        "def get_response(new_prompt):\n",
        "    response = openai.Completion.create(\n",
        "    engine=\"davinci-instruct-beta\",\n",
        "    prompt=new_prompt,\n",
        "    temperature=0.25,\n",
        "    max_tokens=100,\n",
        "    top_p=1)\n",
        "\n",
        "    return response"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vs6DJHkiSL6Y"
      },
      "source": [
        "#### Experiment for windows of size 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYGUjWoOG-UA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48341708-b0e4-427e-dcc1-c7e0ecde7a59"
      },
      "source": [
        "# Creating windows of size 3\n",
        "prompt_list = window(preprocess,3)\n",
        "for i in range(len(prompt_list)):\n",
        "  print(prompt_list[i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[\"pavan kumar S:Okay, so, I was working on the use case for react code conversion And code generation also. So on the code generation part, I tried with multiple examples, the accuracy is very less, it comes to 50%. And also if there is a slight deviation in the prompt or something, it gives very bad results. So I think shouldn't consider this code conversion or generation use-case as a right fit using GPT-3. Darshan Melgiri:So do you have any iterations of the training that you have done before you conclude that it is not right Use case to work with GPT 3?\", \"pavan kumar S:Yes, I have taken 10 examples and trained with it, then asked the same questions, like if I take an example of generating a DIV, then ask a DIV with some text, it will give the correct results. But, if I take a form, and if I give form a button, And train it. Then again, if I ask a form with two fields and two buttons, it doesn't give the right result. So basic component, it's not able to generate So that's why I think it's not a good use case and it's failing. It Darshan Melgiri: Okay, so if I have to consider it right in terms of the code conversion or generation, it is better to exclude gpt3 And then build our own self products rather than relying upon the openAI platform. \", \"Darshan Melgiri : So also I wanted to update that I was working on this Text summarization use case. So this is coming out pretty well. So we have went with a different approaches.  Darshan Melgiri : So basically three approaches were put in place. One approach was directly taking the entire conversation and extracting the summary. The second approach was mostly in terms of Taking the topics with respect to one individual and then briefing, it accordingly. The third one was To ensure to move the window size. Starting from let's say first five lines, followed by the next five and see how the results were getting generated to be very honest. For the first two approaches, it was not that great, but while we put on the moving Windows Slide the results were getting better. So yet to understand if it still works for this particular use case.\"]\n",
            "[\"pavan kumar S:Yes, I have taken 10 examples and trained with it, then asked the same questions, like if I take an example of generating a DIV, then ask a DIV with some text, it will give the correct results. But, if I take a form, and if I give form a button, And train it. Then again, if I ask a form with two fields and two buttons, it doesn't give the right result. So basic component, it's not able to generate So that's why I think it's not a good use case and it's failing. It Darshan Melgiri: Okay, so if I have to consider it right in terms of the code conversion or generation, it is better to exclude gpt3 And then build our own self products rather than relying upon the openAI platform. \", \"Darshan Melgiri : So also I wanted to update that I was working on this Text summarization use case. So this is coming out pretty well. So we have went with a different approaches.  Darshan Melgiri : So basically three approaches were put in place. One approach was directly taking the entire conversation and extracting the summary. The second approach was mostly in terms of Taking the topics with respect to one individual and then briefing, it accordingly. The third one was To ensure to move the window size. Starting from let's say first five lines, followed by the next five and see how the results were getting generated to be very honest. For the first two approaches, it was not that great, but while we put on the moving Windows Slide the results were getting better. So yet to understand if it still works for this particular use case.\", \"pavan kumar S: Okay, cool. Darshan Melgiri : Okay, then, so if I have to summarize, then the use case on the text summarization using gpt3 is pretty good. So it's a thumbs up for that and thumbs down for the use cases Wherein gpt3 is used for the code conversion or the code Migration part of it. Is that correct?\"]\n",
            "[\"Darshan Melgiri : So also I wanted to update that I was working on this Text summarization use case. So this is coming out pretty well. So we have went with a different approaches.  Darshan Melgiri : So basically three approaches were put in place. One approach was directly taking the entire conversation and extracting the summary. The second approach was mostly in terms of Taking the topics with respect to one individual and then briefing, it accordingly. The third one was To ensure to move the window size. Starting from let's say first five lines, followed by the next five and see how the results were getting generated to be very honest. For the first two approaches, it was not that great, but while we put on the moving Windows Slide the results were getting better. So yet to understand if it still works for this particular use case.\", \"pavan kumar S: Okay, cool. Darshan Melgiri : Okay, then, so if I have to summarize, then the use case on the text summarization using gpt3 is pretty good. So it's a thumbs up for that and thumbs down for the use cases Wherein gpt3 is used for the code conversion or the code Migration part of it. Is that correct?\", \"pavan kumar S:Yes, absolutely. Darshan Melgiri: Oh okay. Okay then so let's see how do we progress further? Thanks man.\"]\n",
            "[\"pavan kumar S: Okay, cool. Darshan Melgiri : Okay, then, so if I have to summarize, then the use case on the text summarization using gpt3 is pretty good. So it's a thumbs up for that and thumbs down for the use cases Wherein gpt3 is used for the code conversion or the code Migration part of it. Is that correct?\", \"pavan kumar S:Yes, absolutely. Darshan Melgiri: Oh okay. Okay then so let's see how do we progress further? Thanks man.\"]\n",
            "[\"pavan kumar S:Yes, absolutely. Darshan Melgiri: Oh okay. Okay then so let's see how do we progress further? Thanks man.\"]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsdo0I9yG-UB"
      },
      "source": [
        "# List of sentences for which the summaries will be extracted\n",
        "con_list = []\n",
        "for prompt in prompt_list:\n",
        "    new_prompt = '. '.join([str(sentence) for sentence in prompt])\n",
        "    new_prompt = new_prompt + \" \\n\\nSummarise the conversation\"\n",
        "    con_list.append(new_prompt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEIpNmuTG-UF",
        "scrolled": false
      },
      "source": [
        "# List of responses (summaries) for the input list of sentences\n",
        "response_list = []\n",
        "for prompt in con_list:\n",
        "    \n",
        "    response_list.append(get_response(prompt))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OB6E4Jc2SL6Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b4c6f56-389b-45f0-a9e9-940f6174f5c7"
      },
      "source": [
        "# Results for windows of size 3 \n",
        "for n, i in enumerate(response_list):\n",
        "    print('\\n\\nSummary of Window #'+str(n+1)+' '+i.choices[0].text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Summary of Window #1 \n",
            "\n",
            "Darshan Melgiri: Okay, so, I was working on the use case for react code conversion And code generation also. So on the code generation part, I tried with multiple examples, the accuracy is very less, it comes to 50%. And also if there is a slight deviation in the prompt or something, it gives very bad results. So I think shouldn't consider this code conversion or generation use-case as a right fit using GPT-3.\n",
            "\n",
            "p\n",
            "\n",
            "\n",
            "Summary of Window #2 \n",
            "\n",
            "Darshan Melgiri: Okay, so if I have to consider it right in terms of the code conversion or generation, it is better to exclude gpt3 And then build our own self products rather than relying upon the openAI platform.\n",
            "\n",
            "Darshan Melgiri: So also I wanted to update that I was working on this Text summarization use case. So this is coming out pretty well. So we have went with a different approaches.\n",
            "\n",
            "Darsh\n",
            "\n",
            "\n",
            "Summary of Window #3 \n",
            "\n",
            "Darshan Melgiri: So also I wanted to update that I was working on this Text summarization use case. So this is coming out pretty well. So we have went with a different approaches. \n",
            "\n",
            "Darshan Melgiri: So basically three approaches were put in place. One approach was directly taking the entire conversation and extracting the summary. The second approach was mostly in terms of Taking the topics with respect to one individual and then briefing, it accordingly. The\n",
            "\n",
            "\n",
            "Summary of Window #4 \n",
            "\n",
            "Darshan Melgiri: So, if I have to summarize, then the use case on the text summarization using gpt3 is pretty good. So it's a thumbs up for that and thumbs down for the use cases Wherein gpt3 is used for the code conversion or the code Migration part of it. Is that correct?\n",
            "\n",
            "Pavan Kumar S: Yes, absolutely.\n",
            "\n",
            "\n",
            "Summary of Window #5 \n",
            "\n",
            "Darshan Melgiri is looking for a new job and is interested in the position of a software engineer. He is looking for a job in the US and is willing to relocate. He has a bachelor's degree in computer science and is looking for a job in the US.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84Zl4rbTSL6a"
      },
      "source": [
        "#### Experiment for windows of size 5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7kdm4M1SL6a"
      },
      "source": [
        "# Creating windows of size 5\n",
        "prompt_list = window(preprocess,5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocC1TyanSL6a"
      },
      "source": [
        "# List of sentences for which the summaries will be extracted\n",
        "con_list = []\n",
        "for prompt in prompt_list:\n",
        "    new_prompt = '. '.join([str(sentence) for sentence in prompt])\n",
        "    new_prompt = new_prompt + \" \\n\\nSummarise the conversation\"\n",
        "    con_list.append(new_prompt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kf6xnUEwG-UG"
      },
      "source": [
        "# List of responses (summaries) for the input list of sentences\n",
        "response_list = []\n",
        "for prompt in con_list:\n",
        "    \n",
        "    response_list.append(get_response(prompt))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbzquQZQSL6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cba3928c-9ff4-4824-9cfa-dbfcaf56a6be"
      },
      "source": [
        "# Results for windows of size 5 \n",
        "for n, i in enumerate(response_list):\n",
        "    print('\\n\\nSummary of Window #'+str(n+1)+' '+i.choices[0].text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Summary of Window #1 \n",
            "\n",
            "The conversation is about the use case of code conversion or generation. The speaker is not sure if it is a good use case to use GPT-3 for. The speaker has tried it with 10 examples and found that it is not accurate. The speaker also tried it with text summarization and found that it is good.\n",
            "\n",
            "\n",
            "Summary of Window #2 \n",
            "\n",
            "Darshan Melgiri: So also I wanted to update that I was working on this Text summarization use case. So this is coming out pretty well. So we have went with a different approaches. \n",
            "\n",
            "Darshan Melgiri : So basically three approaches were put in place. One approach was directly taking the entire conversation and extracting the summary. The second approach was mostly in terms of Taking the topics with respect to one individual and then briefing, it accordingly. The\n",
            "\n",
            "\n",
            "Summary of Window #3 \n",
            "\n",
            "Darshan Melgiri: So also I wanted to update that I was working on this Text summarization use case. So this is coming out pretty well. So we have went with a different approaches. \n",
            "\n",
            "Darshan Melgiri: So basically three approaches were put in place. One approach was directly taking the entire conversation and extracting the summary. The second approach was mostly in terms of Taking the topics with respect to one individual and then briefing, it accordingly. The\n",
            "\n",
            "\n",
            "Summary of Window #4 \n",
            "\n",
            "Darshan Melgiri is looking for a way to convert his code from one language to another. He is not satisfied with the results of the use case where gpt3 is used for the code conversion.\n",
            "\n",
            "\n",
            "Summary of Window #5 \n",
            "\n",
            "The customer is looking for a solution to his problem. The customer is not sure if he needs a new phone or a new SIM card. The customer has been told that he needs a new SIM card.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qiFEtxxSL6b"
      },
      "source": [
        "#### Experiment for windows of size 6"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Hkr1AFoSL6c"
      },
      "source": [
        "# Creating windows of size 6\n",
        "prompt_list = window(preprocess,6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJlYSckTSL6c"
      },
      "source": [
        "# List of sentences for which the summaries will be extracted\n",
        "con_list = []\n",
        "for prompt in prompt_list:\n",
        "    new_prompt = '. '.join([str(sentence) for sentence in prompt])\n",
        "    new_prompt = new_prompt + \" \\n\\nSummarise the conversation\"\n",
        "    con_list.append(new_prompt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHR75xb1SL6d"
      },
      "source": [
        "# List of responses (summaries) for the input list of sentences\n",
        "response_list = []\n",
        "for prompt in con_list:\n",
        "    \n",
        "    response_list.append(get_response(prompt))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guYT7UDsSL6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed38dbf1-2c48-4f9f-9481-d02778bc2654"
      },
      "source": [
        "# Results for windows of size 6\n",
        "for n, i in enumerate(response_list):\n",
        "    print('\\n\\nSummary of Window #'+str(n+1)+' '+i.choices[0].text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Summary of Window #1 \n",
            "\n",
            "Darshan Melgiri: Okay, so if I have to consider it right in terms of the code conversion or generation, it is better to exclude gpt3 And then build our own self products rather than relying upon the openAI platform.\n",
            "\n",
            "pavan kumar S: Yes, absolutely.\n",
            "\n",
            "\n",
            "Summary of Window #2 \n",
            "\n",
            "Darshan Melgiri: So also I wanted to update that I was working on this Text summarization use case. So this is coming out pretty well. So we have went with a different approaches. \n",
            "\n",
            "Darshan Melgiri: So basically three approaches were put in place. One approach was directly taking the entire conversation and extracting the summary. The second approach was mostly in terms of Taking the topics with respect to one individual and then briefing, it accordingly. The\n",
            "\n",
            "\n",
            "Summary of Window #3 \n",
            "\n",
            "Darshan Melgiri : So also I wanted to update that I was working on this Text summarization use case. So this is coming out pretty well. So we have went with a different approaches. \n",
            "\n",
            "Darshan Melgiri : So basically three approaches were put in place. One approach was directly taking the entire conversation and extracting the summary. The second approach was mostly in terms of Taking the topics with respect to one individual and then briefing, it accordingly. The\n",
            "\n",
            "\n",
            "Summary of Window #4 \n",
            "\n",
            "Darshan Melgiri: Okay, so if I have to summarize, then the use case on the text summarization using gpt3 is pretty good. So it's a thumbs up for that and thumbs down for the use cases Wherein gpt3 is used for the code conversion or the code Migration part of it. Is that correct?\n",
            "\n",
            "Pavan Kumar: Yes, absolutely.\n",
            "\n",
            "\n",
            "Summary of Window #5 \n",
            "\n",
            "The customer is interested in the product and wants to know more about the product.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_P2TP-YvSL6e"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "027tXXeISL6e"
      },
      "source": [
        "### Text summarization on a hearing transcript "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_AFgcnyNvvs"
      },
      "source": [
        "hearing_prompt = \"\"\"Meeting of CTAS County Commission-Transcript of Dialogue\n",
        "Chairman Wormsley (at the proper time and place, after taking the chair and striking the gavel on the\n",
        "table): This meeting of the CTAS County Commission will come to order. Clerk please call the role. (Ensure that a majority of the members are present.)\n",
        "Chairman Wormsley: Each of you has received the agenda. I will entertain a motion that the agenda be\n",
        "approved.\n",
        "Commissioner Brown: So moved.\n",
        "Commissioner Hobbs: Seconded\n",
        "Chairman Wormsley: It has been moved and seconded that the agenda be approved as received by\n",
        "the members. All those in favor signify by saying \"Aye\"?...Opposed by saying \"No\"?...The agenda is approved. You have received a copy of the minutes of the last meeting. Are there any corrections or additions to the meeting?\n",
        "Commissioner McCroskey: Mister Chairman, my name has been omitted from the Special Committee on\n",
        "Indigent Care.\n",
        "Chairman Wormsley: Thank you. If there are no objections, the minutes will be corrected to include the\n",
        "name of Commissioner McCroskey. Will the clerk please make this correction. Any further corrections?\n",
        "Seeing none, without objection the minutes will stand approved as read. (This is sort of a short cut way\n",
        "that is commonly used for approval of minutes and/or the agenda rather than requiring a motion and second.)\n",
        "Chairman Wormsley: Commissioner Adkins, the first item on the agenda is yours.\n",
        "Commissioner Adkins: Mister Chairman, I would like to make a motion to approve the resolution taking\n",
        "money from the Data Processing Reserve Account in the County Clerk's office and moving it to the equipment line to purchase a laptop computer.\n",
        "Commissioner Carmical: I second the motion.\n",
        "Chairman Wormsley: This resolution has a motion and second. Will the clerk please take the vote.\n",
        "Chairman Wormsley: The resolution passes. We will now take up old business. At our last meeting, Commissioner McKee, your motion to sell property near the airport was deferred to this meeting. You are\n",
        "recognized.\n",
        "Commissioner McKee: I move to withdraw that motion.\n",
        "Chairman Wormsley: Commissioner McKee has moved to withdraw his motion to sell property near the\n",
        "airport. Seeing no objection, this motion is withdrawn. The next item on the agenda is Commissioner\n",
        "Rodgers'.\n",
        "Commissioner Rodgers: I move adopton of the resolution previously provided to each of you to increase\n",
        "the state match local litigation tax in circuit, chancery, and criminal courts to the maximum amounts permissible. This resolution calls for the increases to go to the general fund.\n",
        "Chairman Wormsley: Commissioner Duckett\n",
        "Commissioner Duckett: The sheriff is opposed to this increase.\n",
        "Chairman Wormsley: Commissioner, you are out of order because this motion has not been seconded as\n",
        "needed before the floor is open for discussion or debate. Discussion will begin after we have a second.\n",
        "Is there a second?\n",
        "Commissioner Reinhart: For purposes of discussion, I second the motion.\n",
        "Chairman Wormsley: Commissioner Rodgers is recognized.\n",
        "CTAS e-Li Sample Meeting Transcript\n",
        "Commissioner Rodgers: (Speaks about the data on collections, handing out all sorts of numerical figures\n",
        "regarding the litigation tax, and the county's need for additional revenue.)\n",
        "Chairman Wormsley: Commissioner Duckett\n",
        "Commissioner Duckett: I move an amendment to the motion to require 25 percent of the proceeds from\n",
        "the increase in the tax on criminal cases go to fund the sheriff's department.\n",
        "Chairman Wormsley: Commissioner Malone\n",
        "Commissioner Malone: I second the amendment.\n",
        "Chairman Wormsley: A motion has been made and seconded to amend the motion to increase the state\n",
        "match local litigation taxes to the maximum amounts to require 25 percent of the proceeds from the increase in the tax on criminal cases in courts of record going to fund the sheriff's department. Any discussion? Will all those in favor please raise your hand? All those opposed please raise your hand. The\n",
        "amendment carries 17-2. We are now on the motion as amended. Any further discussion?\n",
        "Commissioner Headrick: Does this require a two-thirds vote?\n",
        "Chairman Wormsley: Will the county attorney answer that question?\n",
        "County Attorney Fults: Since these are only courts of record, a majority vote will pass it. The two-thirds\n",
        "requirement is for the general sessions taxes.\n",
        "Chairman Wormsley: Other questions or discussion? Commissioner Adams.\n",
        "Commissioner Adams: Move for a roll call vote.\n",
        "Commissioner Crenshaw: Second\n",
        "Chairman Wormsley: The motion has been made and seconded that the state match local litigation taxes\n",
        "be increased to the maximum amounts allowed by law with 25 percent of the proceeds from the increase\n",
        "in the tax on criminal cases in courts of record going to fund the sheriff's department. Will all those in\n",
        "favor please vote as the clerk calls your name, those in favor vote \"aye,\" those against vote \"no.\" Nine\n",
        "votes for, nine votes against, one not voting. The increase fails. We are now on new business. Commissioner Adkins, the first item on the agenda is yours.\n",
        "Commissioner Adkins: Each of you has previously received a copy of a resolution to increase the wheel\n",
        "tax by $10 to make up the state cut in education funding. I move adoption of this resolution.\n",
        "Chairman Wormsley: Commissioner Thompson\n",
        "Commissioner Thompson: I second.\n",
        "Chairman Wormsley: It has been properly moved and seconded that a resolution increasing the wheel\n",
        "tax by $10 to make up the state cut in education funding be passed. Any discussion? (At this point numerous county commissioners speak for and against increasing the wheel tax and making up the education\n",
        "cuts. This is the first time this resolution is under consideration.) Commissioner Hayes is recognized.\n",
        "Commissioner Hayes: I move previous question.\n",
        "Commisioner Crenshaw: Second.\n",
        "Chairman Wormsley: Previous question has been moved and seconded. As you know, a motion for previous question, if passed by a two-thirds vote, will cut off further debate and require us to vote yes or no\n",
        "on the resolution before us. You should vote for this motion if you wish to cut off further debate of the\n",
        "wheel tax increase at this point. Will all those in favor of previous question please raise your hand? Will\n",
        "all those against please raise your hand? The vote is 17-2. Previous question passes. We are now on\n",
        "the motion to increase the wheel tax by $10 to make up the state cut in education funding. Will all those\n",
        "in favor please raise your hand? Will all those against please raise your hand? The vote is 17-2. This\n",
        "increase passes on first passage. Is there any other new business? Since no member is seeking recognition, are there announcements? Commissioner Hailey.\n",
        "Commissioner Hailey: There will be a meeting of the Budget Committee to look at solid waste funding\n",
        "recommendations on Tuesday, July 16 at noon here in this room.\n",
        "Chairman Wormsley: Any other announcements? The next meeting of this body will be Monday, August\n",
        "19 at 7 p.m., here in this room. Commissioner Carmical.\n",
        "Commissioner Carmical: There will be a chili supper at County Elementary School on August 16 at 6:30\n",
        "p.m. Everyone is invited.\n",
        "CTAS e-Li Sample Meeting Transcript\n",
        "Chairman Wormsley: Commissioner Austin.\n",
        "Commissioner Austin: Move adjournment.\n",
        "Commissioner Garland: Second.\n",
        "Chairman Wormsley: Without objection, the meeting will stand adjourned.\n",
        "\n",
        "\n",
        "Summarise in 10 lines or less\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4R-JQ91SL6f",
        "outputId": "217d2ea8-b5aa-47f4-ea2d-0fe799d273c6"
      },
      "source": [
        "# Get summary as a response from GPT3\n",
        "response = openai.Completion.create(\n",
        "  engine=\"davinci-instruct-beta\",\n",
        "  prompt=hearing_prompt,\n",
        "  temperature=0.25,\n",
        "  max_tokens=100,\n",
        "  top_p=1\n",
        ")\n",
        "\n",
        "print(response.choices[0].text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "The CTAS County Commission met to discuss the agenda items. The first item on the agenda was a motion to approve the resolution taking money from the Data Processing Reserve Account in the County Clerk's office and moving it to the equipment line to purchase a laptop computer. The motion passed. The next item on the agenda was Commissioner Rodgers' motion to increase the state match local litigation tax in circuit, chancery, and criminal courts to the maximum amounts permissible. The motion was amended to require 25\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fT85x739SL6f"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}